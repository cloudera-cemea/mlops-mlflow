{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97cd394a",
   "metadata": {},
   "source": [
    "# Track Predictions and Custom Metrics Locally\n",
    "\n",
    "This notebook shows a full example how to set up a decorated prediction function and test it locally, based on the **logged** model from the previous lab.\n",
    "\n",
    "- ✅ Load the MLflow model from logged artifacts based on accuracy.\n",
    "- ✅ Set up a decorated prediction function to log metrics during inference.\n",
    "- ✅ Test the metrics store locally in \"development\" mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "efa2edca-4cab-4755-93d2-a0161409d406",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best model from artifacts location: /home/cdsw/.experiments/6yxz-cbhb-5jsi-afk2/tag1-yyl1-367x-rjfl/artifacts\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "import cml.metrics_v1 as metrics\n",
    "import cml.models_v1 as models\n",
    "\n",
    "# Configuration for experiment and model\n",
    "EXPERIMENT_NAME = \"sklearn_experiment_lab_2\"\n",
    "MODEL_ARTIFACT_LOCATION = \"logistic_regression\"\n",
    "\n",
    "# Load the best performing model from MLflow based on accuracy\n",
    "run_results = mlflow.search_runs(experiment_names=[EXPERIMENT_NAME])\n",
    "best_run_artifact_uri = run_results.loc[run_results[\"metrics.accuracy\"].idxmax(), \"artifact_uri\"]\n",
    "model = mlflow.pyfunc.load_model(f\"{best_run_artifact_uri}/{MODEL_ARTIFACT_LOCATION}\")\n",
    "print(f\"Loaded best model from artifacts location: {best_run_artifact_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "33c980d5-7475-4d37-bfac-be059d5a7ae5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Not running in a model replica, so using a local development\n",
      "version of the model metrics service. Please use the following\n",
      "CRN's to consume metrics:\n",
      "   model_crn: \"crn:cdp:ml:::workspace:dev/model\" (cml.metrics.dev_model_crn)\n",
      "   model_build_crn: \"crn:cdp:ml:::workspace:dev/model-build\" (cml.metrics.dev_model_build_crn)\n",
      "   model_deployment_crn: \"crn:cdp:ml:::workspace:dev/model-deployment\" (cml.metrics.dev_model_deployment_crn)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The model_metrics decorator equips the predict function to\n",
    "# call track_metrics. It also changes the return type. If the\n",
    "# raw predict function returns a value \"result\", the wrapped\n",
    "# function will return eg\n",
    "# {\n",
    "#   \"uuid\": \"612a0f17-33ad-4c41-8944-df15183ac5bd\",\n",
    "#   \"prediction\": \"result\"\n",
    "# }\n",
    "# The UUID can be used to query the stored metrics for this\n",
    "# prediction later.\n",
    "@models.cml_model(metrics=True)\n",
    "def predict(inputs: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Make predictions with the model while tracking metrics.\n",
    "    \n",
    "    Args:\n",
    "        inputs: DataFrame containing input features\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing:\n",
    "        - prediction: The model's prediction\n",
    "        - uuid: Unique identifier for tracking this prediction's metrics\n",
    "    \"\"\"\n",
    "    # Track the input features for monitoring\n",
    "    metrics.track_metric(\"input\", inputs[\"inputs\"][0])\n",
    "\n",
    "    # Run model inference\n",
    "    result = model.predict(inputs)\n",
    "\n",
    "    # Track the prediction output\n",
    "    metrics.track_metric(\"output\", str(result[0]))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "739b8178-1f7f-438d-9b61-f5208b8012c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction': array([0]),\n",
       " 'model_deployment_crn': 'crn:cdp:ml:::workspace:dev/model-deployment',\n",
       " 'uuid': '5f94cb41-eb5b-4b8b-a750-67874f7d4aad'}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define example input and invoke predict function with metrics\n",
    "example_input = pd.DataFrame({\"inputs\": [[4.6, 3.6, 1.0, 0.2]]})\n",
    "prediction = predict(example_input)\n",
    "\n",
    "prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
